<!DOCTYPE html>
<html lang="en">
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebRTC Client</title>
    <style>
        canvas {
            border: 1px solid black;
        }
    </style>
</head>
<body>
    <h1>WebSocket Client</h1>
    <p id="audioStatus">Audio status: Not connected</p>
    <img id="streamImage" alt="Streaming Image" />
    <audio id="remoteAudio" autoplay></audio>
    <canvas id="audioCanvas" width="640" height="100"></canvas>

    <script>
        const socket = new WebSocket('wss://projectvertexscape.onrender.com/ws/jsonScene/');
        let peerConnection;
        let localStream;
        let audioTrack;
        const config = {
            iceServers: [{ urls: 'stun:stun.l.google.com:19302' }]
        };

        async function start() {
            try {
                // Request access to the microphone
                localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                document.getElementById('audioStatus').innerText = "Microphone access granted";

                // Create peer connection and add local stream
                createPeerConnection();
                audioTrack = localStream.getAudioTracks()[0];
                peerConnection.addTrack(audioTrack, localStream);
                visualizeAudio(localStream);
            } catch (err) {
                console.error('Error accessing media devices.', err);
                document.getElementById('audioStatus').innerText = "Microphone access denied";
            }
        }

        function visualizeAudio(stream) {
            const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            const source = audioCtx.createMediaStreamSource(stream);
            const analyser = audioCtx.createAnalyser();
            analyser.fftSize = 2048;
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);

            source.connect(analyser);

            const canvas = document.getElementById('audioCanvas');
            const canvasCtx = canvas.getContext('2d');

            function draw() {
                requestAnimationFrame(draw);

                analyser.getByteTimeDomainData(dataArray);

                canvasCtx.fillStyle = 'rgb(200, 200, 200)';
                canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

                canvasCtx.lineWidth = 2;
                canvasCtx.strokeStyle = 'rgb(0, 0, 0)';

                canvasCtx.beginPath();

                const sliceWidth = canvas.width * 1.0 / bufferLength;
                let x = 0;

                for (let i = 0; i < bufferLength; i++) {
                    const v = dataArray[i] / 128.0;
                    const y = v * canvas.height / 2;

                    if (i === 0) {
                        canvasCtx.moveTo(x, y);
                    } else {
                        canvasCtx.lineTo(x, y);
                    }

                    x += sliceWidth;
                }

                canvasCtx.lineTo(canvas.width, canvas.height / 2);
                canvasCtx.stroke();
            }

            draw();
        }

        socket.onopen = function(event) {
            console.log('WebSocket connection established');
            // Suscribirse al grupo de clientes web
            socket.send(JSON.stringify({
                'command': 'subscribe',
                'group': 'web_clients_group',
            }));
        };

        socket.onmessage = async function(event) {
            console.log('Received data from server');

            if (typeof event.data === "string") {
                const message = JSON.parse(event.data);

                if (!peerConnection) {
                    createPeerConnection();
                }

                if (message.type === 'offer') {
                    console.log('Received offer:', message.sdp);
                    if (peerConnection.signalingState !== 'stable' && peerConnection.signalingState !== 'have-remote-offer') {
                        console.error('Received offer in invalid state:', peerConnection.signalingState);
                        return;
                    }
                    await peerConnection.setRemoteDescription(new RTCSessionDescription({ type: 'offer', sdp: message.sdp }));
                    const answer = await peerConnection.createAnswer();
                    await peerConnection.setLocalDescription(answer);
                    socket.send(JSON.stringify({ type: 'answer', sdp: answer.sdp }));
                } else if (message.type === 'ice') {
                    console.log('Received ICE candidate:', message.candidate);
                    const candidate = new RTCIceCandidate({ sdpMLineIndex: message.sdpMLineIndex, candidate: message.candidate });
                    await peerConnection.addIceCandidate(candidate);
                }
            } else if (event.data instanceof Blob) {
                const reader = new FileReader();
                reader.onload = function() {
                    const arrayBuffer = this.result;
                    const blob = new Blob([new Uint8Array(arrayBuffer)], { type: 'image/jpeg' });
                    const url = URL.createObjectURL(blob);
                    document.getElementById('streamImage').src = url;
                };
                reader.readAsArrayBuffer(event.data);
            }
        };

        function createPeerConnection() {
            peerConnection = new RTCPeerConnection(config);

            peerConnection.onicecandidate = function(event) {
                if (event.candidate) {
                    console.log('Sending ICE candidate:', event.candidate);
                    socket.send(JSON.stringify({ type: 'ice', candidate: event.candidate.candidate, sdpMid: event.candidate.sdpMid, sdpMLineIndex: event.candidate.sdpMLineIndex }));
                }
            };

            peerConnection.ontrack = function(event) {
                console.log('Track received:', event.track);
                document.getElementById('remoteAudio').srcObject = event.streams[0];
                document.getElementById('audioStatus').innerText = "Audio status: Connected";
            };

            peerConnection.oniceconnectionstatechange = function() {
                console.log('ICE connection state change:', peerConnection.iceConnectionState);
            };

            peerConnection.onsignalingstatechange = function() {
                console.log('Signaling state change:', peerConnection.signalingState);
            };
        }

        socket.onerror = function(error) {
            console.error('WebSocket error:', error);
        };

        socket.onclose = function(event) {
            console.log('WebSocket connection closed:', event.code, event.reason);
        };

        window.addEventListener('beforeunload', () => {
            socket.close();
        });

        start(); // Start the process of requesting microphone access and initializing WebRTC
    </script>
</body>
</html>
